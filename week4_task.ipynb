{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "import seaborn as sns\n",
    "sns.set_style()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from xgboost import XGBClassfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>Mother's occupation</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "      <th>total_grade_1st_sem</th>\n",
       "      <th>total_grade_2nd_sem</th>\n",
       "      <th>admission_grade_per_age</th>\n",
       "      <th>log_course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.365000</td>\n",
       "      <td>5.141664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.277778</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>9.132811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.568421</td>\n",
       "      <td>9.112728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>1</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>5.980000</td>\n",
       "      <td>9.187379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "      <td>5.388889</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>3.144444</td>\n",
       "      <td>8.988945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  \\\n",
       "0               1                17                  5   \n",
       "1               1                15                  1   \n",
       "2               1                 1                  5   \n",
       "3               1                17                  2   \n",
       "4               2                39                  1   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "\n",
       "   Father's qualification  Mother's occupation  ...  \\\n",
       "0                      12                    5  ...   \n",
       "1                       3                    3  ...   \n",
       "2                      37                    9  ...   \n",
       "3                      37                    5  ...   \n",
       "4                      38                    9  ...   \n",
       "\n",
       "   Curricular units 2nd sem (grade)  \\\n",
       "0                          0.000000   \n",
       "1                         13.666667   \n",
       "2                          0.000000   \n",
       "3                         12.400000   \n",
       "4                         13.000000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "\n",
       "   Inflation rate   GDP  Target  total_grade_1st_sem  total_grade_2nd_sem  \\\n",
       "0             1.4  1.74       0             0.000000             0.000000   \n",
       "1            -0.3  0.79       1             5.333333             5.277778   \n",
       "2             1.4  1.74       0             1.000000             1.000000   \n",
       "3            -0.8 -3.12       1             5.571429             5.566667   \n",
       "4            -0.3  0.79       1             5.388889             5.166667   \n",
       "\n",
       "   admission_grade_per_age  log_course  \n",
       "0                 6.365000    5.141664  \n",
       "1                 7.500000    9.132811  \n",
       "2                 6.568421    9.112728  \n",
       "3                 5.980000    9.187379  \n",
       "4                 3.144444    8.988945  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('new_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4424 entries, 0 to 4423\n",
      "Data columns (total 40 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Marital status                                  4424 non-null   int64  \n",
      " 1   Application mode                                4424 non-null   int64  \n",
      " 2   Application order                               4424 non-null   int64  \n",
      " 3   Daytime/evening attendance\t                     4424 non-null   int64  \n",
      " 4   Previous qualification                          4424 non-null   int64  \n",
      " 5   Previous qualification (grade)                  4424 non-null   float64\n",
      " 6   Nacionality                                     4424 non-null   int64  \n",
      " 7   Mother's qualification                          4424 non-null   int64  \n",
      " 8   Father's qualification                          4424 non-null   int64  \n",
      " 9   Mother's occupation                             4424 non-null   int64  \n",
      " 10  Father's occupation                             4424 non-null   int64  \n",
      " 11  Admission grade                                 4424 non-null   float64\n",
      " 12  Displaced                                       4424 non-null   int64  \n",
      " 13  Educational special needs                       4424 non-null   int64  \n",
      " 14  Debtor                                          4424 non-null   int64  \n",
      " 15  Tuition fees up to date                         4424 non-null   int64  \n",
      " 16  Gender                                          4424 non-null   int64  \n",
      " 17  Scholarship holder                              4424 non-null   int64  \n",
      " 18  Age at enrollment                               4424 non-null   int64  \n",
      " 19  International                                   4424 non-null   int64  \n",
      " 20  Curricular units 1st sem (credited)             4424 non-null   int64  \n",
      " 21  Curricular units 1st sem (enrolled)             4424 non-null   int64  \n",
      " 22  Curricular units 1st sem (evaluations)          4424 non-null   int64  \n",
      " 23  Curricular units 1st sem (approved)             4424 non-null   int64  \n",
      " 24  Curricular units 1st sem (grade)                4424 non-null   float64\n",
      " 25  Curricular units 1st sem (without evaluations)  4424 non-null   int64  \n",
      " 26  Curricular units 2nd sem (credited)             4424 non-null   int64  \n",
      " 27  Curricular units 2nd sem (enrolled)             4424 non-null   int64  \n",
      " 28  Curricular units 2nd sem (evaluations)          4424 non-null   int64  \n",
      " 29  Curricular units 2nd sem (approved)             4424 non-null   int64  \n",
      " 30  Curricular units 2nd sem (grade)                4424 non-null   float64\n",
      " 31  Curricular units 2nd sem (without evaluations)  4424 non-null   int64  \n",
      " 32  Unemployment rate                               4424 non-null   float64\n",
      " 33  Inflation rate                                  4424 non-null   float64\n",
      " 34  GDP                                             4424 non-null   float64\n",
      " 35  Target                                          4424 non-null   int64  \n",
      " 36  total_grade_1st_sem                             4424 non-null   float64\n",
      " 37  total_grade_2nd_sem                             4424 non-null   float64\n",
      " 38  admission_grade_per_age                         4424 non-null   float64\n",
      " 39  log_course                                      4424 non-null   float64\n",
      "dtypes: float64(11), int64(29)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0    2215\n",
       "1    2209\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital status                                    0\n",
       "Application mode                                  0\n",
       "Application order                                 0\n",
       "Daytime/evening attendance\\t                      0\n",
       "Previous qualification                            0\n",
       "Previous qualification (grade)                    0\n",
       "Nacionality                                       0\n",
       "Mother's qualification                            0\n",
       "Father's qualification                            0\n",
       "Mother's occupation                               0\n",
       "Father's occupation                               0\n",
       "Admission grade                                   0\n",
       "Displaced                                         0\n",
       "Educational special needs                         0\n",
       "Debtor                                            0\n",
       "Tuition fees up to date                           0\n",
       "Gender                                            0\n",
       "Scholarship holder                                0\n",
       "Age at enrollment                                 0\n",
       "International                                     0\n",
       "Curricular units 1st sem (credited)               0\n",
       "Curricular units 1st sem (enrolled)               0\n",
       "Curricular units 1st sem (evaluations)            0\n",
       "Curricular units 1st sem (approved)               0\n",
       "Curricular units 1st sem (grade)                  0\n",
       "Curricular units 1st sem (without evaluations)    0\n",
       "Curricular units 2nd sem (credited)               0\n",
       "Curricular units 2nd sem (enrolled)               0\n",
       "Curricular units 2nd sem (evaluations)            0\n",
       "Curricular units 2nd sem (approved)               0\n",
       "Curricular units 2nd sem (grade)                  0\n",
       "Curricular units 2nd sem (without evaluations)    0\n",
       "Unemployment rate                                 0\n",
       "Inflation rate                                    0\n",
       "GDP                                               0\n",
       "Target                                            0\n",
       "total_grade_1st_sem                               0\n",
       "total_grade_2nd_sem                               0\n",
       "admission_grade_per_age                           0\n",
       "log_course                                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there are no duplicates in the data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are no object variables\n",
    "#since this is the dataset that has already been cleaned, we will go straight to the task at hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train and test sets\n",
    "x = df.drop('Target',axis = 1)\n",
    "y = df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[:2000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2654.4"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6 *4424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>Mother's occupation</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>total_grade_1st_sem</th>\n",
       "      <th>total_grade_2nd_sem</th>\n",
       "      <th>admission_grade_per_age</th>\n",
       "      <th>log_course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-0.095470</td>\n",
       "      <td>2.490896</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.804841</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>-0.036018</td>\n",
       "      <td>-0.669778</td>\n",
       "      <td>-0.225661</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.471527</td>\n",
       "      <td>-1.963489</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.287638</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.765761</td>\n",
       "      <td>-2.278085</td>\n",
       "      <td>-2.311974</td>\n",
       "      <td>0.337225</td>\n",
       "      <td>-4.180214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-0.209869</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>2.076819</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>-1.189759</td>\n",
       "      <td>-1.256427</td>\n",
       "      <td>-0.301375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>0.659562</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>-1.105222</td>\n",
       "      <td>0.347199</td>\n",
       "      <td>0.091473</td>\n",
       "      <td>0.156953</td>\n",
       "      <td>1.108152</td>\n",
       "      <td>0.223817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>2.490896</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.804841</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.117723</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>-0.074233</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.471527</td>\n",
       "      <td>-1.963489</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.287638</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.765761</td>\n",
       "      <td>-1.833793</td>\n",
       "      <td>-1.844177</td>\n",
       "      <td>0.475395</td>\n",
       "      <td>0.201656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-0.095470</td>\n",
       "      <td>0.207173</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.804841</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.181819</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>-0.225661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.416450</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.813253</td>\n",
       "      <td>-1.466871</td>\n",
       "      <td>-1.375511</td>\n",
       "      <td>0.197257</td>\n",
       "      <td>0.292094</td>\n",
       "      <td>0.075721</td>\n",
       "      <td>0.284030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.356212</td>\n",
       "      <td>1.162916</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>-2.856470</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-2.473171</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.117723</td>\n",
       "      <td>1.024985</td>\n",
       "      <td>-0.074233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>0.531608</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>-1.105222</td>\n",
       "      <td>0.347199</td>\n",
       "      <td>0.116156</td>\n",
       "      <td>0.104975</td>\n",
       "      <td>-1.850276</td>\n",
       "      <td>0.065069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>3.252137</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.577342</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>-1.189759</td>\n",
       "      <td>-1.386793</td>\n",
       "      <td>-0.225661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.467631</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>1.476924</td>\n",
       "      <td>1.137005</td>\n",
       "      <td>-1.789667</td>\n",
       "      <td>0.061854</td>\n",
       "      <td>0.156953</td>\n",
       "      <td>0.382447</td>\n",
       "      <td>0.284030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>0.207173</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.956508</td>\n",
       "      <td>14.916228</td>\n",
       "      <td>-1.189759</td>\n",
       "      <td>-1.386793</td>\n",
       "      <td>-0.074233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.808050</td>\n",
       "      <td>0.147747</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.175007</td>\n",
       "      <td>-0.454253</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>-0.056624</td>\n",
       "      <td>-0.362821</td>\n",
       "      <td>0.504391</td>\n",
       "      <td>0.284030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>1.621820</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.117723</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>-0.074233</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.139788</td>\n",
       "      <td>0.627573</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>-1.105222</td>\n",
       "      <td>0.347199</td>\n",
       "      <td>0.455237</td>\n",
       "      <td>0.143958</td>\n",
       "      <td>-0.601246</td>\n",
       "      <td>0.252767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>3.593483</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.117723</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>-0.149947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.339678</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.813253</td>\n",
       "      <td>-1.466871</td>\n",
       "      <td>-1.375511</td>\n",
       "      <td>-0.145483</td>\n",
       "      <td>-0.128923</td>\n",
       "      <td>1.237206</td>\n",
       "      <td>0.210984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-0.495866</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>1.470154</td>\n",
       "      <td>2.911135</td>\n",
       "      <td>1.181819</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>-0.225661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>0.531608</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.425695</td>\n",
       "      <td>1.787974</td>\n",
       "      <td>-0.749872</td>\n",
       "      <td>0.066790</td>\n",
       "      <td>0.104975</td>\n",
       "      <td>0.706788</td>\n",
       "      <td>0.284030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4424 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Marital status  Application mode  Application order  \\\n",
       "0          -0.294829         -0.095470           2.490896   \n",
       "1          -0.294829         -0.209869          -0.554068   \n",
       "2          -0.294829         -1.010660           2.490896   \n",
       "3          -0.294829         -0.095470           0.207173   \n",
       "4           1.356212          1.162916          -0.554068   \n",
       "...              ...               ...                ...   \n",
       "4419       -0.294829         -1.010660           3.252137   \n",
       "4420       -0.294829         -1.010660           0.207173   \n",
       "4421       -0.294829         -1.010660          -0.554068   \n",
       "4422       -0.294829         -1.010660          -0.554068   \n",
       "4423       -0.294829         -0.495866          -0.554068   \n",
       "\n",
       "      Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                         0.350082                -0.35023   \n",
       "1                         0.350082                -0.35023   \n",
       "2                         0.350082                -0.35023   \n",
       "3                         0.350082                -0.35023   \n",
       "4                        -2.856470                -0.35023   \n",
       "...                            ...                     ...   \n",
       "4419                      0.350082                -0.35023   \n",
       "4420                      0.350082                -0.35023   \n",
       "4421                      0.350082                -0.35023   \n",
       "4422                      0.350082                -0.35023   \n",
       "4423                      0.350082                -0.35023   \n",
       "\n",
       "      Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                          -0.804841    -0.126298               -0.036018   \n",
       "1                           2.076819    -0.126298               -1.189759   \n",
       "2                          -0.804841    -0.126298                1.117723   \n",
       "3                          -0.804841    -0.126298                1.181819   \n",
       "4                          -2.473171    -0.126298                1.117723   \n",
       "...                              ...          ...                     ...   \n",
       "4419                       -0.577342    -0.126298               -1.189759   \n",
       "4420                       -0.956508    14.916228               -1.189759   \n",
       "4421                        1.621820    -0.126298                1.117723   \n",
       "4422                        3.593483    -0.126298                1.117723   \n",
       "4423                        1.470154     2.911135                1.181819   \n",
       "\n",
       "      Father's qualification  Mother's occupation  ...  \\\n",
       "0                  -0.669778            -0.225661  ...   \n",
       "1                  -1.256427            -0.301375  ...   \n",
       "2                   0.959802            -0.074233  ...   \n",
       "3                   0.959802            -0.225661  ...   \n",
       "4                   1.024985            -0.074233  ...   \n",
       "...                      ...                  ...  ...   \n",
       "4419               -1.386793            -0.225661  ...   \n",
       "4420               -1.386793            -0.074233  ...   \n",
       "4421                0.959802            -0.074233  ...   \n",
       "4422                0.959802            -0.149947  ...   \n",
       "4423                0.959802            -0.225661  ...   \n",
       "\n",
       "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                               -1.471527                         -1.963489   \n",
       "1                                0.518904                          0.659562   \n",
       "2                               -1.471527                         -1.963489   \n",
       "3                                0.187165                          0.416450   \n",
       "4                                0.518904                          0.531608   \n",
       "...                                   ...                               ...   \n",
       "4419                             0.187165                          0.467631   \n",
       "4420                            -0.808050                          0.147747   \n",
       "4421                            -1.139788                          0.627573   \n",
       "4422                             0.187165                          0.339678   \n",
       "4423                             0.518904                          0.531608   \n",
       "\n",
       "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                          -0.199441          -0.287638   \n",
       "1                                          -0.199441           0.876222   \n",
       "2                                          -0.199441          -0.287638   \n",
       "3                                          -0.199441          -0.813253   \n",
       "4                                          -0.199441           0.876222   \n",
       "...                                              ...                ...   \n",
       "4419                                       -0.199441           1.476924   \n",
       "4420                                       -0.199441          -0.175007   \n",
       "4421                                       -0.199441           0.876222   \n",
       "4422                                       -0.199441          -0.813253   \n",
       "4423                                       -0.199441           0.425695   \n",
       "\n",
       "      Inflation rate       GDP  total_grade_1st_sem  total_grade_2nd_sem  \\\n",
       "0           0.124386  0.765761            -2.278085            -2.311974   \n",
       "1          -1.105222  0.347199             0.091473             0.156953   \n",
       "2           0.124386  0.765761            -1.833793            -1.844177   \n",
       "3          -1.466871 -1.375511             0.197257             0.292094   \n",
       "4          -1.105222  0.347199             0.116156             0.104975   \n",
       "...              ...       ...                  ...                  ...   \n",
       "4419        1.137005 -1.789667             0.061854             0.156953   \n",
       "4420       -0.454253  0.889126            -0.056624            -0.362821   \n",
       "4421       -1.105222  0.347199             0.455237             0.143958   \n",
       "4422       -1.466871 -1.375511            -0.145483            -0.128923   \n",
       "4423        1.787974 -0.749872             0.066790             0.104975   \n",
       "\n",
       "      admission_grade_per_age  log_course  \n",
       "0                    0.337225   -4.180214  \n",
       "1                    1.108152    0.223817  \n",
       "2                    0.475395    0.201656  \n",
       "3                    0.075721    0.284030  \n",
       "4                   -1.850276    0.065069  \n",
       "...                       ...         ...  \n",
       "4419                 0.382447    0.284030  \n",
       "4420                 0.504391    0.284030  \n",
       "4421                -0.601246    0.252767  \n",
       "4422                 1.237206    0.210984  \n",
       "4423                 0.706788    0.284030  \n",
       "\n",
       "[4424 rows x 39 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaling the x values to have the values on the same scale\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "x_scaled = pd.DataFrame(x_scaled,columns=x.columns)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train sets\n",
    "x_train = x_scaled.iloc[:2650,:]\n",
    "y_train = y.iloc[:2650]\n",
    "\n",
    "#validation sets\n",
    "x_val = x_scaled.iloc[2650:3650,:]\n",
    "y_val = y.iloc[2650:3650]\n",
    "\n",
    "#test sets\n",
    "x_test = x_scaled.iloc[3650:,:]\n",
    "y_test = y.iloc[3650:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2650, 39), (2650,), (774, 39), (774,), (1000, 39), (1000,))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape,x_val.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the baseline model, Logistic Regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8539622641509435"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.843"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.84150943 0.83018868 0.83396226 0.85849057 0.84528302]\n",
      "Mean cross-validation score: 0.8418867924528304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(log_model, x_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the train and validation model scores are not too far apart, which suggests that the model is not overfitting too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions\n",
    "y_pred = log_model.predict(x_test)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[318,  79],\n",
       "       [ 50, 327]], dtype=int64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(318+327)/(318+327+50+79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83       397\n",
      "           1       0.81      0.87      0.84       377\n",
      "\n",
      "    accuracy                           0.83       774\n",
      "   macro avg       0.83      0.83      0.83       774\n",
      "weighted avg       0.84      0.83      0.83       774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_acc = accuracy_score(y_test,y_pred)\n",
    "log_model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8341907809900514"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(log_model,open('log_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementing traditional machine learning models\n",
    "* Decision trees\n",
    "* Random forests\n",
    "* SVM\n",
    "* Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecisionTreeClassifier': 0.766,\n",
       " 'RandomForestClassifier': 0.844,\n",
       " 'Support Vector Machines': 0.84,\n",
       " 'XGB': 0.842}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "models = {'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
    "          'RandomForestClassifier':RandomForestClassifier(),\n",
    "          'Support Vector Machines':SVC(),\n",
    "          'XGB':XGBClassifier()}\n",
    "\n",
    "model_score = {}\n",
    "def fit_and_score(models,x_train,y_train,x_val,y_val):\n",
    "\n",
    "    for name,model in models.items():\n",
    "        model.fit(x_train,y_train)\n",
    "        model_score[name] = model.score(x_val,y_val)\n",
    "    return model_score\n",
    "fit_and_score(models,x_train,y_train,x_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking each model separately\n",
    "#Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_model = DecisionTreeClassifier()\n",
    "dec_model.fit(x_train,y_train)\n",
    "dec_model.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.78301887 0.76792453 0.76792453 0.77735849 0.77735849]\n",
      "Mean cross-validation score: 0.7747169811320755\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(dec_model, x_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dec_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       397\n",
      "           1       0.78      0.78      0.78       377\n",
      "\n",
      "    accuracy                           0.79       774\n",
      "   macro avg       0.79      0.79      0.79       774\n",
      "weighted avg       0.79      0.79      0.79       774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7855297157622739"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_model_acc = accuracy_score(y_test,y_pred)\n",
    "dec_model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[313,  84],\n",
       "       [ 82, 295]], dtype=int64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7854532334685206"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dec_model,open('dec_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomforest model\n",
    "\n",
    "rand_model = RandomForestClassifier()\n",
    "rand_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.845"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_model.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rand_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.82830189 0.83207547 0.85660377 0.84339623 0.83962264]\n",
      "Mean cross-validation score: 0.8400000000000001\n"
     ]
    }
   ],
   "source": [
    "cross_val = cross_val_score(rand_model,x_train,y_train,cv=5)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cross_val)\n",
    "print(\"Mean cross-validation score:\", cross_val.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83       397\n",
      "           1       0.80      0.88      0.84       377\n",
      "\n",
      "    accuracy                           0.83       774\n",
      "   macro avg       0.84      0.84      0.83       774\n",
      "weighted avg       0.84      0.83      0.83       774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_model_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356506691432428"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rand_model,open('rand_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores are  [0.82264151 0.80566038 0.8245283  0.84528302 0.84339623]\n",
      "Mean score is  0.8283018867924528\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(svc,x_train,y_train,cv = 5)\n",
    "\n",
    "print('Scores are ',cv_scores)\n",
    "print(\"Mean score is \", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81       397\n",
      "           1       0.77      0.87      0.82       377\n",
      "\n",
      "    accuracy                           0.81       774\n",
      "   macro avg       0.82      0.82      0.81       774\n",
      "weighted avg       0.82      0.81      0.81       774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.813953488372093"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8154327215388624"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[301,  96],\n",
       "       [ 48, 329]], dtype=int64)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svc,open('svc_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train,y_train)\n",
    "xgb.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores are  [0.83962264 0.83396226 0.8490566  0.84339623 0.85283019]\n",
      "Mean score is  0.8437735849056605\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(xgb,x_train,y_train,cv = 5)\n",
    "\n",
    "print('Scores are ',cv_scores)\n",
    "print(\"Mean score is \", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.83       397\n",
      "           1       0.80      0.87      0.83       377\n",
      "\n",
      "    accuracy                           0.83       774\n",
      "   macro avg       0.83      0.83      0.83       774\n",
      "weighted avg       0.83      0.83      0.83       774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[315,  82],\n",
       "       [ 50, 327]], dtype=int64)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8304124434585652"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb,open('xgb_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_table = pd.DataFrame([dec_model_acc,log_model_acc,rand_model_acc,xgb_acc,svc_acc],columns=['accuracy'],\n",
    "                         index=['DecisionTrees',\n",
    "                                'LogisticRegression',\n",
    "                                'RandomForestClassifier',\n",
    "                                'XGBClassifier',\n",
    "                                'SVC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTrees</th>\n",
       "      <td>0.785530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.834625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.829457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.813953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy\n",
       "DecisionTrees           0.785530\n",
       "LogisticRegression      0.833333\n",
       "RandomForestClassifier  0.834625\n",
       "XGBClassifier           0.829457\n",
       "SVC                     0.813953"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_table.accuracy.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#of the tradtional models, Randomforest has the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(24,input_shape=(39,),activation = 'relu'),\n",
    "    keras.layers.Dense(12,activation = 'relu'),\n",
    "    keras.layers.Dense(4,activation = 'relu'),\n",
    "    #keras.layers.Dense(2,activation = 'relu'),\n",
    "    keras.layers.Dense(1,activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 24)                960       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 12)                300       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4)                 52        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1317 (5.14 KB)\n",
      "Trainable params: 1317 (5.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - 3s 10ms/step - loss: 0.6662 - accuracy: 0.6242 - val_loss: 0.6124 - val_accuracy: 0.7470\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7713 - val_loss: 0.4675 - val_accuracy: 0.8060\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8181 - val_loss: 0.3967 - val_accuracy: 0.8250\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8374 - val_loss: 0.3725 - val_accuracy: 0.8310\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8423 - val_loss: 0.3662 - val_accuracy: 0.8330\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8479 - val_loss: 0.3624 - val_accuracy: 0.8340\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8555 - val_loss: 0.3557 - val_accuracy: 0.8380\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8532 - val_loss: 0.3561 - val_accuracy: 0.8310\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.8551 - val_loss: 0.3538 - val_accuracy: 0.8400\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8585 - val_loss: 0.3503 - val_accuracy: 0.8450\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8634 - val_loss: 0.3486 - val_accuracy: 0.8400\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8596 - val_loss: 0.3473 - val_accuracy: 0.8420\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8634 - val_loss: 0.3530 - val_accuracy: 0.8330\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3065 - accuracy: 0.8660 - val_loss: 0.3498 - val_accuracy: 0.8420\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.3020 - accuracy: 0.8649 - val_loss: 0.3521 - val_accuracy: 0.8380\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8706 - val_loss: 0.3469 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8691 - val_loss: 0.3458 - val_accuracy: 0.8400\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.8702 - val_loss: 0.3510 - val_accuracy: 0.8430\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8713 - val_loss: 0.3493 - val_accuracy: 0.8430\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2840 - accuracy: 0.8755 - val_loss: 0.3566 - val_accuracy: 0.8390\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.8740 - val_loss: 0.3517 - val_accuracy: 0.8430\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8770 - val_loss: 0.3560 - val_accuracy: 0.8370\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.8777 - val_loss: 0.3531 - val_accuracy: 0.8450\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2748 - accuracy: 0.8792 - val_loss: 0.3500 - val_accuracy: 0.8470\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2702 - accuracy: 0.8838 - val_loss: 0.3601 - val_accuracy: 0.8420\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8830 - val_loss: 0.3556 - val_accuracy: 0.8400\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.8834 - val_loss: 0.3598 - val_accuracy: 0.8410\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8868 - val_loss: 0.3640 - val_accuracy: 0.8390\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.8857 - val_loss: 0.3618 - val_accuracy: 0.8380\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2580 - accuracy: 0.8860 - val_loss: 0.3664 - val_accuracy: 0.8380\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.8940 - val_loss: 0.3643 - val_accuracy: 0.8400\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2545 - accuracy: 0.8879 - val_loss: 0.3630 - val_accuracy: 0.8410\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2520 - accuracy: 0.8925 - val_loss: 0.3740 - val_accuracy: 0.8420\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2488 - accuracy: 0.8906 - val_loss: 0.3762 - val_accuracy: 0.8410\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.8936 - val_loss: 0.3784 - val_accuracy: 0.8330\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.8958 - val_loss: 0.3730 - val_accuracy: 0.8420\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2413 - accuracy: 0.8943 - val_loss: 0.3819 - val_accuracy: 0.8400\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2396 - accuracy: 0.9015 - val_loss: 0.3830 - val_accuracy: 0.8450\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2377 - accuracy: 0.9008 - val_loss: 0.4012 - val_accuracy: 0.8410\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2372 - accuracy: 0.9015 - val_loss: 0.4002 - val_accuracy: 0.8390\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2333 - accuracy: 0.9038 - val_loss: 0.3872 - val_accuracy: 0.8330\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2308 - accuracy: 0.9049 - val_loss: 0.3904 - val_accuracy: 0.8450\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.9072 - val_loss: 0.3894 - val_accuracy: 0.8350\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.9015 - val_loss: 0.4057 - val_accuracy: 0.8380\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.9026 - val_loss: 0.4075 - val_accuracy: 0.8390\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.9042 - val_loss: 0.4031 - val_accuracy: 0.8410\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2230 - accuracy: 0.9068 - val_loss: 0.4098 - val_accuracy: 0.8350\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9125 - val_loss: 0.4086 - val_accuracy: 0.8390\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2156 - accuracy: 0.9140 - val_loss: 0.4203 - val_accuracy: 0.8410\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.2144 - accuracy: 0.9155 - val_loss: 0.4205 - val_accuracy: 0.8410\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.9151 - val_loss: 0.4187 - val_accuracy: 0.8440\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2096 - accuracy: 0.9189 - val_loss: 0.4306 - val_accuracy: 0.8370\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2084 - accuracy: 0.9147 - val_loss: 0.4343 - val_accuracy: 0.8360\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.9189 - val_loss: 0.4277 - val_accuracy: 0.8400\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.2048 - accuracy: 0.9219 - val_loss: 0.4448 - val_accuracy: 0.8350\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2042 - accuracy: 0.9185 - val_loss: 0.4398 - val_accuracy: 0.8340\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9204 - val_loss: 0.4489 - val_accuracy: 0.8370\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2006 - accuracy: 0.9211 - val_loss: 0.4557 - val_accuracy: 0.8430\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9196 - val_loss: 0.4583 - val_accuracy: 0.8350\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1975 - accuracy: 0.9238 - val_loss: 0.4513 - val_accuracy: 0.8440\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1951 - accuracy: 0.9234 - val_loss: 0.4708 - val_accuracy: 0.8350\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1929 - accuracy: 0.9279 - val_loss: 0.4629 - val_accuracy: 0.8350\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1914 - accuracy: 0.9230 - val_loss: 0.4776 - val_accuracy: 0.8270\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1916 - accuracy: 0.9283 - val_loss: 0.4788 - val_accuracy: 0.8330\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9223 - val_loss: 0.4881 - val_accuracy: 0.8330\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1856 - accuracy: 0.9245 - val_loss: 0.4961 - val_accuracy: 0.8340\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1843 - accuracy: 0.9275 - val_loss: 0.5023 - val_accuracy: 0.8300\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9253 - val_loss: 0.4996 - val_accuracy: 0.8300\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1799 - accuracy: 0.9253 - val_loss: 0.5007 - val_accuracy: 0.8250\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.9306 - val_loss: 0.5027 - val_accuracy: 0.8300\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9283 - val_loss: 0.5086 - val_accuracy: 0.8300\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9302 - val_loss: 0.5372 - val_accuracy: 0.8340\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.9291 - val_loss: 0.5308 - val_accuracy: 0.8260\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1719 - accuracy: 0.9302 - val_loss: 0.5489 - val_accuracy: 0.8310\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9343 - val_loss: 0.5353 - val_accuracy: 0.8320\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9347 - val_loss: 0.5573 - val_accuracy: 0.8140\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9358 - val_loss: 0.5591 - val_accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9340 - val_loss: 0.5553 - val_accuracy: 0.8340\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9328 - val_loss: 0.5684 - val_accuracy: 0.8330\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1652 - accuracy: 0.9374 - val_loss: 0.5743 - val_accuracy: 0.8240\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1610 - accuracy: 0.9389 - val_loss: 0.5749 - val_accuracy: 0.8240\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1604 - accuracy: 0.9381 - val_loss: 0.5881 - val_accuracy: 0.8220\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.9377 - val_loss: 0.5960 - val_accuracy: 0.8250\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1569 - accuracy: 0.9362 - val_loss: 0.5990 - val_accuracy: 0.8230\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1579 - accuracy: 0.9419 - val_loss: 0.6094 - val_accuracy: 0.8240\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1554 - accuracy: 0.9392 - val_loss: 0.6180 - val_accuracy: 0.8310\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9404 - val_loss: 0.6204 - val_accuracy: 0.8280\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1508 - accuracy: 0.9408 - val_loss: 0.6232 - val_accuracy: 0.8220\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9419 - val_loss: 0.6433 - val_accuracy: 0.8280\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 0.9392 - val_loss: 0.6305 - val_accuracy: 0.8230\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9445 - val_loss: 0.6381 - val_accuracy: 0.8230\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9411 - val_loss: 0.6629 - val_accuracy: 0.8120\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9423 - val_loss: 0.6543 - val_accuracy: 0.8170\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9460 - val_loss: 0.6651 - val_accuracy: 0.8130\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9438 - val_loss: 0.6593 - val_accuracy: 0.8210\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.9479 - val_loss: 0.6797 - val_accuracy: 0.8200\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9453 - val_loss: 0.6704 - val_accuracy: 0.8110\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9442 - val_loss: 0.6903 - val_accuracy: 0.8090\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9453 - val_loss: 0.6979 - val_accuracy: 0.8120\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9475 - val_loss: 0.7071 - val_accuracy: 0.8170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x253755a5610>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train, validation_data=(x_val,y_val),epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99993324e-01],\n",
       "       [7.29632971e-04],\n",
       "       [9.95938241e-01],\n",
       "       [4.93893474e-01],\n",
       "       [9.07540679e-01],\n",
       "       [9.85728025e-01],\n",
       "       [2.84601271e-01],\n",
       "       [8.37180734e-01],\n",
       "       [9.96715248e-01],\n",
       "       [7.21347606e-05],\n",
       "       [7.08167785e-17],\n",
       "       [9.99675989e-01],\n",
       "       [9.56886530e-01],\n",
       "       [9.52724099e-01],\n",
       "       [9.65086162e-01],\n",
       "       [4.85667199e-01],\n",
       "       [3.76237440e-04],\n",
       "       [1.05137859e-15],\n",
       "       [9.94252503e-01],\n",
       "       [5.10922790e-01],\n",
       "       [9.99319375e-01],\n",
       "       [9.99982834e-01],\n",
       "       [9.93960202e-01],\n",
       "       [7.29245126e-01],\n",
       "       [9.18255091e-01],\n",
       "       [9.96294141e-01],\n",
       "       [2.68985084e-13],\n",
       "       [9.90005712e-13],\n",
       "       [9.96298671e-01],\n",
       "       [9.61653888e-01],\n",
       "       [4.06795036e-04],\n",
       "       [2.78471161e-05],\n",
       "       [8.17135061e-25],\n",
       "       [5.30870690e-04],\n",
       "       [5.35141362e-06],\n",
       "       [7.57496238e-01],\n",
       "       [9.59386051e-01],\n",
       "       [3.38008928e-17],\n",
       "       [1.94781450e-07],\n",
       "       [8.79378498e-01],\n",
       "       [1.80039657e-04],\n",
       "       [6.04971175e-15],\n",
       "       [9.61917548e-17],\n",
       "       [2.87889183e-04],\n",
       "       [2.70065684e-02],\n",
       "       [3.94879858e-11],\n",
       "       [9.82372642e-01],\n",
       "       [3.97845433e-05],\n",
       "       [1.14653327e-01],\n",
       "       [1.92998575e-15],\n",
       "       [1.67459145e-01],\n",
       "       [4.04778421e-01],\n",
       "       [1.89670392e-15],\n",
       "       [9.31401317e-18],\n",
       "       [9.87328053e-01],\n",
       "       [1.49917215e-01],\n",
       "       [1.50475219e-01],\n",
       "       [3.58991250e-02],\n",
       "       [3.87362479e-06],\n",
       "       [4.99934219e-02],\n",
       "       [9.99079645e-01],\n",
       "       [5.28638124e-01],\n",
       "       [8.07274424e-04],\n",
       "       [1.12421866e-15],\n",
       "       [7.30427533e-24],\n",
       "       [1.39523772e-05],\n",
       "       [4.24039364e-08],\n",
       "       [7.09754467e-01],\n",
       "       [1.58057920e-13],\n",
       "       [6.35689412e-09],\n",
       "       [3.79661449e-16],\n",
       "       [1.17879778e-27],\n",
       "       [1.73173653e-17],\n",
       "       [1.92494312e-10],\n",
       "       [9.47147608e-01],\n",
       "       [1.97237059e-05],\n",
       "       [3.61364441e-24],\n",
       "       [9.87324212e-03],\n",
       "       [9.15258646e-01],\n",
       "       [9.99499559e-01],\n",
       "       [8.08342993e-01],\n",
       "       [1.89612197e-11],\n",
       "       [8.14336002e-01],\n",
       "       [9.98383284e-01],\n",
       "       [3.48527869e-03],\n",
       "       [9.80512619e-01],\n",
       "       [7.11185753e-01],\n",
       "       [4.05693660e-04],\n",
       "       [7.24780798e-01],\n",
       "       [1.01441132e-12],\n",
       "       [5.12499392e-01],\n",
       "       [8.39614630e-01],\n",
       "       [9.93334532e-01],\n",
       "       [7.73632705e-01],\n",
       "       [8.19070206e-17],\n",
       "       [3.78836674e-04],\n",
       "       [9.85093951e-01],\n",
       "       [8.92738314e-11],\n",
       "       [1.03911214e-18],\n",
       "       [9.62394595e-01],\n",
       "       [9.92635965e-01],\n",
       "       [9.99904394e-01],\n",
       "       [7.31073201e-01],\n",
       "       [9.91123915e-01],\n",
       "       [2.63911914e-27],\n",
       "       [9.57883060e-01],\n",
       "       [7.89445937e-01],\n",
       "       [9.68356133e-01],\n",
       "       [7.31027350e-02],\n",
       "       [2.48312087e-21],\n",
       "       [6.63833767e-02],\n",
       "       [6.05149382e-21],\n",
       "       [9.63769972e-01],\n",
       "       [8.36944699e-01],\n",
       "       [8.98967922e-01],\n",
       "       [9.30467904e-01],\n",
       "       [9.57081735e-01],\n",
       "       [5.17902063e-21],\n",
       "       [7.02828348e-01],\n",
       "       [8.39551687e-01],\n",
       "       [2.39176584e-23],\n",
       "       [2.94506133e-01],\n",
       "       [9.24836040e-01],\n",
       "       [7.50982171e-24],\n",
       "       [9.87557352e-01],\n",
       "       [5.37242166e-14],\n",
       "       [8.72084365e-06],\n",
       "       [8.43925774e-01],\n",
       "       [1.77795140e-04],\n",
       "       [1.85783008e-12],\n",
       "       [5.50927818e-01],\n",
       "       [9.52786922e-01],\n",
       "       [9.38530684e-01],\n",
       "       [6.61549926e-01],\n",
       "       [2.12530953e-08],\n",
       "       [1.73372464e-04],\n",
       "       [8.54791343e-01],\n",
       "       [9.15712645e-12],\n",
       "       [7.24055827e-01],\n",
       "       [1.44024096e-16],\n",
       "       [5.56559265e-01],\n",
       "       [4.06559835e-08],\n",
       "       [3.10308323e-16],\n",
       "       [2.38217341e-19],\n",
       "       [3.69752158e-08],\n",
       "       [9.87748981e-01],\n",
       "       [7.03610957e-01],\n",
       "       [3.98926798e-19],\n",
       "       [9.87513483e-01],\n",
       "       [1.12468491e-25],\n",
       "       [2.64839947e-18],\n",
       "       [9.96997893e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99860525e-01],\n",
       "       [7.36778835e-04],\n",
       "       [2.60153932e-13],\n",
       "       [9.71803367e-01],\n",
       "       [9.99987185e-01],\n",
       "       [9.99932766e-01],\n",
       "       [9.99995053e-01],\n",
       "       [2.01903895e-01],\n",
       "       [1.78713572e-11],\n",
       "       [9.34398849e-04],\n",
       "       [9.59567845e-01],\n",
       "       [9.51088309e-01],\n",
       "       [9.31856155e-01],\n",
       "       [2.63497769e-03],\n",
       "       [9.99999523e-01],\n",
       "       [2.98376868e-19],\n",
       "       [8.33223090e-25],\n",
       "       [6.90217130e-05],\n",
       "       [9.89099695e-17],\n",
       "       [2.14630678e-01],\n",
       "       [5.19742680e-05],\n",
       "       [7.28769010e-08],\n",
       "       [4.35610622e-01],\n",
       "       [7.43826749e-05],\n",
       "       [9.88363147e-01],\n",
       "       [2.11771733e-09],\n",
       "       [6.06868088e-01],\n",
       "       [9.80124474e-01],\n",
       "       [8.86010706e-01],\n",
       "       [2.44938048e-09],\n",
       "       [2.47490420e-20],\n",
       "       [8.95732343e-01],\n",
       "       [2.58554652e-13],\n",
       "       [8.33846967e-12],\n",
       "       [8.34880290e-11],\n",
       "       [4.10886514e-07],\n",
       "       [7.96080846e-03],\n",
       "       [3.29565071e-02],\n",
       "       [5.53263770e-03],\n",
       "       [5.06852026e-11],\n",
       "       [2.87366291e-08],\n",
       "       [9.21139121e-01],\n",
       "       [8.22014417e-20],\n",
       "       [1.03993750e-17],\n",
       "       [4.36683476e-20],\n",
       "       [3.07936988e-12],\n",
       "       [9.96486604e-01],\n",
       "       [2.07983414e-23],\n",
       "       [5.55609986e-02],\n",
       "       [1.31834322e-13],\n",
       "       [1.15248952e-02],\n",
       "       [9.98108180e-19],\n",
       "       [9.72252369e-01],\n",
       "       [4.85667199e-01],\n",
       "       [9.86251891e-01],\n",
       "       [6.53904935e-16],\n",
       "       [1.39591911e-08],\n",
       "       [1.53626024e-05],\n",
       "       [2.00448273e-13],\n",
       "       [6.18058026e-01],\n",
       "       [9.92392778e-01],\n",
       "       [3.08009915e-15],\n",
       "       [6.03566838e-13],\n",
       "       [3.30179215e-23],\n",
       "       [9.97183621e-01],\n",
       "       [2.51694471e-01],\n",
       "       [3.11926145e-11],\n",
       "       [9.11622882e-01],\n",
       "       [9.30304348e-01],\n",
       "       [9.89695847e-01],\n",
       "       [2.65340800e-16],\n",
       "       [1.54067589e-21],\n",
       "       [1.19357003e-22],\n",
       "       [9.80976284e-01],\n",
       "       [9.99735296e-01],\n",
       "       [8.66472244e-01],\n",
       "       [9.95721400e-01],\n",
       "       [9.96648550e-01],\n",
       "       [9.81455326e-01],\n",
       "       [1.21872120e-06],\n",
       "       [2.36476168e-01],\n",
       "       [8.78100157e-01],\n",
       "       [9.83301699e-01],\n",
       "       [9.80958462e-01],\n",
       "       [1.01000853e-01],\n",
       "       [9.53994572e-01],\n",
       "       [9.74417210e-01],\n",
       "       [9.99951720e-01],\n",
       "       [9.07958508e-01],\n",
       "       [3.50621760e-01],\n",
       "       [3.55040643e-17],\n",
       "       [2.33368501e-02],\n",
       "       [8.94924998e-01],\n",
       "       [3.04331836e-13],\n",
       "       [9.21315372e-01],\n",
       "       [9.97618318e-01],\n",
       "       [7.68931806e-01],\n",
       "       [9.57858741e-01],\n",
       "       [1.11311674e-03],\n",
       "       [2.37646531e-02],\n",
       "       [2.19327265e-11],\n",
       "       [1.01100141e-21],\n",
       "       [9.99445558e-01],\n",
       "       [9.86585915e-01],\n",
       "       [2.62677995e-03],\n",
       "       [9.99007285e-01],\n",
       "       [3.21375677e-26],\n",
       "       [8.33274841e-01],\n",
       "       [8.83477405e-02],\n",
       "       [1.20633110e-01],\n",
       "       [1.51029706e-03],\n",
       "       [4.21747984e-11],\n",
       "       [8.43397677e-01],\n",
       "       [9.85793531e-01],\n",
       "       [9.53972340e-01],\n",
       "       [9.29888666e-01],\n",
       "       [3.66978645e-01],\n",
       "       [9.98439565e-02],\n",
       "       [9.92722452e-01],\n",
       "       [9.83615816e-01],\n",
       "       [9.99999046e-01],\n",
       "       [2.69024801e-02],\n",
       "       [4.29984708e-16],\n",
       "       [9.96499836e-01],\n",
       "       [1.18701560e-02],\n",
       "       [3.03729296e-01],\n",
       "       [5.06308209e-03],\n",
       "       [9.99051988e-01],\n",
       "       [8.49740684e-01],\n",
       "       [9.98847604e-01],\n",
       "       [8.94066687e-09],\n",
       "       [1.13189389e-18],\n",
       "       [4.10012417e-02],\n",
       "       [7.06449255e-09],\n",
       "       [1.53464614e-04],\n",
       "       [9.79213893e-01],\n",
       "       [9.91842151e-01],\n",
       "       [4.98583354e-03],\n",
       "       [8.50838766e-22],\n",
       "       [8.14386070e-01],\n",
       "       [6.62188185e-25],\n",
       "       [1.10435983e-23],\n",
       "       [9.97793317e-01],\n",
       "       [3.49754751e-01],\n",
       "       [4.92062689e-25],\n",
       "       [9.97702956e-01],\n",
       "       [9.70018506e-01],\n",
       "       [6.78166673e-02],\n",
       "       [3.13011715e-13],\n",
       "       [9.89666700e-01],\n",
       "       [9.95026469e-01],\n",
       "       [2.30569945e-08],\n",
       "       [5.20380428e-25],\n",
       "       [4.90877837e-01],\n",
       "       [4.37263340e-01],\n",
       "       [9.94126618e-01],\n",
       "       [9.68049109e-01],\n",
       "       [4.66790963e-28],\n",
       "       [9.99999642e-01],\n",
       "       [9.73918080e-01],\n",
       "       [1.37933614e-02],\n",
       "       [5.41159001e-12],\n",
       "       [9.80946600e-01],\n",
       "       [5.74693622e-05],\n",
       "       [9.66672409e-20],\n",
       "       [1.71410605e-01],\n",
       "       [1.54809043e-01],\n",
       "       [9.71611381e-01],\n",
       "       [9.53463495e-01],\n",
       "       [9.79703367e-01],\n",
       "       [9.99847233e-01],\n",
       "       [9.74735796e-01],\n",
       "       [9.94204223e-01],\n",
       "       [9.94652569e-01],\n",
       "       [9.70908761e-01],\n",
       "       [9.94431853e-01],\n",
       "       [3.86537790e-01],\n",
       "       [9.69260037e-01],\n",
       "       [6.21687233e-01],\n",
       "       [2.23134637e-01],\n",
       "       [9.84425545e-01],\n",
       "       [8.17383697e-27],\n",
       "       [9.50511932e-01],\n",
       "       [7.51923859e-01],\n",
       "       [8.10149968e-01],\n",
       "       [4.62519228e-01],\n",
       "       [1.25147086e-02],\n",
       "       [9.99997854e-01],\n",
       "       [2.07236781e-06],\n",
       "       [8.47160816e-01],\n",
       "       [9.99838352e-01],\n",
       "       [1.43275997e-02],\n",
       "       [4.13068810e-18],\n",
       "       [1.44816175e-01],\n",
       "       [9.99998987e-01],\n",
       "       [5.21151373e-13],\n",
       "       [4.25599694e-01],\n",
       "       [1.30242030e-24],\n",
       "       [5.99225973e-18],\n",
       "       [9.93243694e-01],\n",
       "       [8.26961339e-01],\n",
       "       [9.28283930e-01],\n",
       "       [1.82552930e-18],\n",
       "       [9.34931755e-01],\n",
       "       [6.38158484e-11],\n",
       "       [1.40354429e-15],\n",
       "       [1.21199910e-17],\n",
       "       [6.65091933e-25],\n",
       "       [2.42676675e-01],\n",
       "       [9.17455835e-23],\n",
       "       [9.97379720e-01],\n",
       "       [9.90480006e-01],\n",
       "       [2.83821108e-04],\n",
       "       [2.74988841e-02],\n",
       "       [2.87570697e-20],\n",
       "       [9.92074013e-01],\n",
       "       [9.82377529e-01],\n",
       "       [5.18271122e-07],\n",
       "       [1.33827463e-01],\n",
       "       [9.21869516e-01],\n",
       "       [4.82492536e-01],\n",
       "       [2.70851484e-12],\n",
       "       [9.99849856e-01],\n",
       "       [5.15520275e-01],\n",
       "       [9.64992702e-01],\n",
       "       [7.16076076e-01],\n",
       "       [9.66213553e-16],\n",
       "       [9.71441329e-01],\n",
       "       [9.99974966e-01],\n",
       "       [6.24390960e-01],\n",
       "       [3.45712304e-01],\n",
       "       [6.23983654e-18],\n",
       "       [5.24543176e-20],\n",
       "       [7.89148390e-01],\n",
       "       [8.23772233e-03],\n",
       "       [5.51065683e-01],\n",
       "       [9.64298904e-01],\n",
       "       [9.63663459e-01],\n",
       "       [9.73896682e-01],\n",
       "       [9.73227918e-01],\n",
       "       [8.76151919e-01],\n",
       "       [9.99941945e-01],\n",
       "       [1.52779123e-25],\n",
       "       [8.57767880e-01],\n",
       "       [8.68762374e-01],\n",
       "       [9.81044292e-01],\n",
       "       [9.82622743e-01],\n",
       "       [2.06082388e-16],\n",
       "       [9.46001768e-01],\n",
       "       [8.66259361e-05],\n",
       "       [9.52282250e-01],\n",
       "       [9.99885619e-01],\n",
       "       [7.81050825e-04],\n",
       "       [1.02484025e-01],\n",
       "       [1.35802664e-03],\n",
       "       [8.52649033e-01],\n",
       "       [1.12076462e-20],\n",
       "       [9.45464253e-01],\n",
       "       [9.63515222e-01],\n",
       "       [9.99888957e-01],\n",
       "       [9.69032884e-01],\n",
       "       [1.00547100e-13],\n",
       "       [9.99551535e-01],\n",
       "       [9.79497015e-01],\n",
       "       [1.32166629e-21],\n",
       "       [8.45066965e-01],\n",
       "       [9.57460582e-01],\n",
       "       [9.92230713e-01],\n",
       "       [5.58524430e-02],\n",
       "       [9.99300122e-01],\n",
       "       [9.69631195e-01],\n",
       "       [9.97491241e-01],\n",
       "       [1.58274414e-22],\n",
       "       [9.95868921e-01],\n",
       "       [1.90721177e-13],\n",
       "       [9.99935746e-01],\n",
       "       [9.84454632e-01],\n",
       "       [2.56523694e-04],\n",
       "       [5.34928830e-08],\n",
       "       [6.16464674e-01],\n",
       "       [9.58183229e-01],\n",
       "       [5.79574566e-26],\n",
       "       [2.64702676e-10],\n",
       "       [9.99560058e-01],\n",
       "       [9.99991357e-01],\n",
       "       [1.40664518e-01],\n",
       "       [1.02047266e-18],\n",
       "       [9.99999106e-01],\n",
       "       [8.73702044e-13],\n",
       "       [1.57016622e-11],\n",
       "       [9.49551105e-01],\n",
       "       [6.40952662e-02],\n",
       "       [9.86894488e-01],\n",
       "       [9.99999642e-01],\n",
       "       [2.05638492e-03],\n",
       "       [2.29671700e-25],\n",
       "       [6.58090523e-19],\n",
       "       [9.36076939e-01],\n",
       "       [9.89163756e-01],\n",
       "       [9.13564205e-01],\n",
       "       [9.47740734e-01],\n",
       "       [9.77276027e-01],\n",
       "       [9.63930845e-01],\n",
       "       [4.58110161e-02],\n",
       "       [2.40584761e-01],\n",
       "       [9.98527646e-01],\n",
       "       [4.29488391e-01],\n",
       "       [9.46665347e-01],\n",
       "       [9.99527812e-01],\n",
       "       [9.99998629e-01],\n",
       "       [2.24148374e-27],\n",
       "       [9.54799056e-01],\n",
       "       [9.26454067e-01],\n",
       "       [5.23944080e-01],\n",
       "       [8.46281350e-01],\n",
       "       [9.60292339e-01],\n",
       "       [2.04993710e-01],\n",
       "       [9.95766521e-01],\n",
       "       [9.80832338e-01],\n",
       "       [9.79422510e-01],\n",
       "       [9.99811351e-01],\n",
       "       [8.56628656e-01],\n",
       "       [9.68235552e-01],\n",
       "       [9.81921673e-01],\n",
       "       [9.98435616e-01],\n",
       "       [2.93620117e-02],\n",
       "       [7.40390956e-01],\n",
       "       [9.97724950e-01],\n",
       "       [9.86957669e-01],\n",
       "       [3.71718716e-06],\n",
       "       [7.63090134e-01],\n",
       "       [9.18603480e-01],\n",
       "       [9.30093884e-01],\n",
       "       [9.99189436e-01],\n",
       "       [9.76240158e-01],\n",
       "       [4.71847266e-01],\n",
       "       [1.01408117e-01],\n",
       "       [3.30261760e-19],\n",
       "       [4.46211100e-02],\n",
       "       [5.46363592e-01],\n",
       "       [2.30295607e-03],\n",
       "       [2.35749528e-01],\n",
       "       [2.45954997e-23],\n",
       "       [6.50741868e-06],\n",
       "       [2.73577339e-08],\n",
       "       [5.40812325e-04],\n",
       "       [6.51523769e-02],\n",
       "       [4.63969588e-01],\n",
       "       [7.39108436e-05],\n",
       "       [9.96818900e-01],\n",
       "       [2.82870471e-01],\n",
       "       [1.53967208e-04],\n",
       "       [9.63014841e-01],\n",
       "       [9.94556606e-01],\n",
       "       [1.52060706e-02],\n",
       "       [7.60044992e-01],\n",
       "       [9.30792153e-01],\n",
       "       [8.73123288e-01],\n",
       "       [9.94083285e-01],\n",
       "       [9.64456797e-01],\n",
       "       [9.86673892e-01],\n",
       "       [2.33508721e-02],\n",
       "       [9.99594271e-01],\n",
       "       [5.13936639e-01],\n",
       "       [9.91856337e-01],\n",
       "       [2.22142413e-01],\n",
       "       [8.59340981e-18],\n",
       "       [2.09874488e-04],\n",
       "       [2.51685433e-05],\n",
       "       [1.18278913e-05],\n",
       "       [9.93389130e-01],\n",
       "       [9.76605237e-01],\n",
       "       [9.98391390e-01],\n",
       "       [8.46152961e-01],\n",
       "       [1.45650756e-05],\n",
       "       [9.77346718e-01],\n",
       "       [9.93440628e-01],\n",
       "       [1.35243894e-07],\n",
       "       [9.95251563e-29],\n",
       "       [2.06172859e-04],\n",
       "       [9.43357795e-02],\n",
       "       [7.60214090e-01],\n",
       "       [1.17895158e-18],\n",
       "       [1.83537509e-03],\n",
       "       [9.27931488e-01],\n",
       "       [9.84509528e-01],\n",
       "       [1.31909337e-05],\n",
       "       [1.76201986e-09],\n",
       "       [8.02324474e-01],\n",
       "       [1.70989595e-02],\n",
       "       [9.03125882e-01],\n",
       "       [1.52955926e-16],\n",
       "       [3.01760167e-01],\n",
       "       [9.92138326e-01],\n",
       "       [9.00471449e-01],\n",
       "       [1.05855899e-04],\n",
       "       [9.77028906e-01],\n",
       "       [2.44485196e-02],\n",
       "       [9.66676176e-01],\n",
       "       [4.08529006e-02],\n",
       "       [9.33147371e-01],\n",
       "       [4.97392148e-01],\n",
       "       [9.71770167e-01],\n",
       "       [9.94285464e-01],\n",
       "       [9.96742487e-01],\n",
       "       [3.29144120e-01],\n",
       "       [9.99993145e-01],\n",
       "       [8.82885516e-01],\n",
       "       [9.88872468e-01],\n",
       "       [9.91899788e-01],\n",
       "       [6.26972003e-04],\n",
       "       [9.93677676e-01],\n",
       "       [4.87909711e-05],\n",
       "       [1.85177051e-15],\n",
       "       [9.56254601e-01],\n",
       "       [9.68559861e-01],\n",
       "       [9.73485887e-01],\n",
       "       [6.33791630e-11],\n",
       "       [2.23148689e-01],\n",
       "       [8.41847181e-01],\n",
       "       [9.90486920e-01],\n",
       "       [9.23093915e-01],\n",
       "       [9.77166116e-01],\n",
       "       [9.84170616e-01],\n",
       "       [9.13281381e-01],\n",
       "       [9.99530196e-01],\n",
       "       [1.55863559e-20],\n",
       "       [9.99845386e-01],\n",
       "       [2.54474330e-09],\n",
       "       [1.57234425e-12],\n",
       "       [9.98125374e-01],\n",
       "       [6.49923801e-01],\n",
       "       [1.90174486e-02],\n",
       "       [9.80977535e-01],\n",
       "       [8.88577163e-01],\n",
       "       [9.76003167e-11],\n",
       "       [9.46641862e-01],\n",
       "       [8.07909489e-01],\n",
       "       [9.51251209e-01],\n",
       "       [3.57037266e-09],\n",
       "       [2.39410594e-01],\n",
       "       [9.61866438e-01],\n",
       "       [2.88970276e-22],\n",
       "       [9.99383974e-06],\n",
       "       [9.88985419e-01],\n",
       "       [2.16213193e-16],\n",
       "       [9.99523699e-01],\n",
       "       [4.50380892e-03],\n",
       "       [9.01428151e-12],\n",
       "       [9.99933124e-01],\n",
       "       [1.44610806e-18],\n",
       "       [2.86079049e-01],\n",
       "       [9.99970675e-01],\n",
       "       [8.61620545e-01],\n",
       "       [3.91773432e-01],\n",
       "       [9.46810961e-01],\n",
       "       [4.67496488e-04],\n",
       "       [2.16066758e-28],\n",
       "       [3.11410520e-03],\n",
       "       [8.96732330e-01],\n",
       "       [3.56352670e-10],\n",
       "       [9.28961933e-01],\n",
       "       [5.62297285e-01],\n",
       "       [5.54505646e-01],\n",
       "       [8.83228302e-01],\n",
       "       [8.98102224e-01],\n",
       "       [3.25664259e-05],\n",
       "       [9.83866930e-01],\n",
       "       [7.54052699e-01],\n",
       "       [8.32684517e-01],\n",
       "       [3.28682654e-04],\n",
       "       [8.71403098e-01],\n",
       "       [3.17272365e-01],\n",
       "       [7.20440790e-23],\n",
       "       [5.33587992e-01],\n",
       "       [9.98690784e-01],\n",
       "       [1.23344913e-18],\n",
       "       [2.66465547e-17],\n",
       "       [1.99356868e-11],\n",
       "       [8.07855395e-04],\n",
       "       [1.81743342e-19],\n",
       "       [9.92975891e-01],\n",
       "       [2.26449483e-04],\n",
       "       [9.52032328e-01],\n",
       "       [1.98695347e-01],\n",
       "       [9.94948373e-13],\n",
       "       [9.47989702e-01],\n",
       "       [9.99131918e-01],\n",
       "       [1.75469946e-02],\n",
       "       [9.93611634e-01],\n",
       "       [5.05490107e-07],\n",
       "       [9.99648392e-01],\n",
       "       [7.18720969e-07],\n",
       "       [1.66976861e-07],\n",
       "       [8.99239182e-01],\n",
       "       [4.08739247e-08],\n",
       "       [1.69766234e-09],\n",
       "       [2.68854409e-01],\n",
       "       [6.67398781e-05],\n",
       "       [9.99759793e-01],\n",
       "       [9.76182401e-01],\n",
       "       [1.65771716e-08],\n",
       "       [3.08049265e-02],\n",
       "       [5.69474396e-23],\n",
       "       [2.05170959e-01],\n",
       "       [4.52036096e-04],\n",
       "       [2.41128713e-01],\n",
       "       [9.73923028e-01],\n",
       "       [9.90645274e-11],\n",
       "       [1.34578020e-08],\n",
       "       [9.99877691e-01],\n",
       "       [1.04032582e-18],\n",
       "       [9.29695234e-05],\n",
       "       [9.99991417e-01],\n",
       "       [9.55761731e-01],\n",
       "       [8.23605299e-01],\n",
       "       [9.62116897e-01],\n",
       "       [9.77646887e-01],\n",
       "       [9.97978091e-01],\n",
       "       [1.72386486e-02],\n",
       "       [1.30400077e-17],\n",
       "       [9.95210290e-01],\n",
       "       [9.07707691e-01],\n",
       "       [6.43043791e-07],\n",
       "       [3.41608112e-20],\n",
       "       [9.97825027e-01],\n",
       "       [9.60874736e-01],\n",
       "       [3.59471772e-21],\n",
       "       [2.95299198e-02],\n",
       "       [8.21314633e-01],\n",
       "       [9.62730110e-01],\n",
       "       [3.21111053e-01],\n",
       "       [1.74946338e-02],\n",
       "       [4.13924954e-06],\n",
       "       [7.54795253e-01],\n",
       "       [8.77084017e-01],\n",
       "       [9.99987602e-01],\n",
       "       [7.29752660e-01],\n",
       "       [9.78169858e-01],\n",
       "       [7.18636962e-04],\n",
       "       [3.52408774e-02],\n",
       "       [3.48967717e-07],\n",
       "       [9.51148391e-01],\n",
       "       [1.52535313e-15],\n",
       "       [7.00420132e-05],\n",
       "       [8.85694146e-01],\n",
       "       [9.99294519e-01],\n",
       "       [9.72937822e-01],\n",
       "       [9.60691988e-01],\n",
       "       [9.29877281e-01],\n",
       "       [1.47777349e-01],\n",
       "       [8.67731154e-01],\n",
       "       [7.54762664e-02],\n",
       "       [2.23727846e-14],\n",
       "       [1.11559838e-10],\n",
       "       [5.23678086e-14],\n",
       "       [9.68586862e-01],\n",
       "       [9.68060970e-01],\n",
       "       [9.94084835e-01],\n",
       "       [9.74442124e-01],\n",
       "       [2.20179879e-14],\n",
       "       [2.07281150e-02],\n",
       "       [7.40773559e-01],\n",
       "       [8.11942220e-01],\n",
       "       [9.61437345e-01],\n",
       "       [1.64973377e-23],\n",
       "       [9.58264351e-01],\n",
       "       [8.08987617e-01],\n",
       "       [9.99792933e-01],\n",
       "       [1.06320125e-20],\n",
       "       [7.89356411e-01],\n",
       "       [1.64498971e-03],\n",
       "       [6.67836112e-22],\n",
       "       [9.99442875e-01],\n",
       "       [9.96128857e-01],\n",
       "       [9.99074399e-01],\n",
       "       [9.73152936e-01],\n",
       "       [2.56586703e-03],\n",
       "       [1.53538918e-14],\n",
       "       [5.73773503e-01],\n",
       "       [9.96287882e-01],\n",
       "       [2.00588070e-11],\n",
       "       [7.96076554e-20],\n",
       "       [1.93520542e-02],\n",
       "       [9.99597669e-01],\n",
       "       [7.73804665e-01],\n",
       "       [9.98178303e-01],\n",
       "       [4.90183771e-01],\n",
       "       [9.64737177e-01],\n",
       "       [9.22340810e-01],\n",
       "       [7.21834681e-07],\n",
       "       [9.77959394e-01],\n",
       "       [9.73820806e-01],\n",
       "       [9.77557600e-01],\n",
       "       [9.36218188e-04],\n",
       "       [7.95111418e-01],\n",
       "       [9.62871253e-01],\n",
       "       [2.22957492e-08],\n",
       "       [1.46738052e-10],\n",
       "       [9.58122134e-01],\n",
       "       [7.02313900e-01],\n",
       "       [7.12780210e-18],\n",
       "       [9.97588217e-01],\n",
       "       [8.26349496e-05],\n",
       "       [9.63545442e-01],\n",
       "       [9.96773005e-01],\n",
       "       [9.51278687e-01],\n",
       "       [6.86246812e-01],\n",
       "       [1.90378558e-02],\n",
       "       [9.95103300e-01],\n",
       "       [7.78686143e-13],\n",
       "       [1.89131275e-01],\n",
       "       [5.81224744e-16],\n",
       "       [9.97132063e-01],\n",
       "       [9.82848883e-01],\n",
       "       [1.60753727e-01],\n",
       "       [6.16126414e-03],\n",
       "       [1.33564045e-05],\n",
       "       [4.67475504e-03],\n",
       "       [9.49841678e-01],\n",
       "       [9.99976337e-01]], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = []\n",
    "for element in y_pred:\n",
    "    if element > 0.45:\n",
    "        y_p.append(1)\n",
    "    \n",
    "    else:\n",
    "        y_p.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[305,  92],\n",
       "       [ 64, 313]], dtype=int64)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7984496124031008"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-((92+64)/(64+92+313+305))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open('dl.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7992503457629837"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
